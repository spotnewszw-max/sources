"""
Database models for news aggregator with think tank and social media features
"""

from sqlalchemy import Column, String, Text, DateTime, Integer, Float, Boolean, ForeignKey, JSON, ARRAY
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from datetime import datetime
import uuid

Base = declarative_base()


class Article(Base):
    """Original news articles from RSS feeds"""
    __tablename__ = "articles"
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    title = Column(String, nullable=False, index=True)
    content = Column(Text)
    url = Column(String, unique=True, nullable=False)
    source = Column(String, nullable=False, index=True)
    author = Column(String)
    published_date = Column(DateTime, index=True)
    fetched_date = Column(DateTime, default=datetime.utcnow, index=True)
    
    # Content analysis
    relevance_score = Column(Float)  # 0-1 Zimbabwe relevance
    category = Column(String)  # Politics, Economy, Tech, etc.
    sentiment = Column(String)  # positive, negative, neutral
    
    # Extracted entities
    mentioned_politicians = Column(JSON)  # List of politicians mentioned
    mentioned_organizations = Column(JSON)  # List of organizations
    mentioned_locations = Column(JSON)  # List of locations
    keywords = Column(JSON)  # Key topics
    
    # Media
    image_url = Column(String)
    image_path = Column(String)  # Local storage path if downloaded
    
    # Status
    is_duplicate = Column(Boolean, default=False)
    duplicate_of = Column(String, ForeignKey("articles.id"))
    is_archived = Column(Boolean, default=False)
    
    # Relationships
    generated_articles = relationship("GeneratedArticle", back_populates="source_article")
    
    def __repr__(self):
        return f"<Article(title='{self.title[:50]}', source='{self.source}')>"


class SocialMediaPost(Base):
    """Social media posts from influencers (Twitter, Facebook, Instagram)"""
    __tablename__ = "social_media_posts"
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    platform = Column(String, nullable=False, index=True)  # twitter, facebook, instagram
    platform_post_id = Column(String, nullable=False)
    
    # Author info
    author_username = Column(String, nullable=False, index=True)
    author_name = Column(String)
    author_follower_count = Column(Integer)
    
    # Content
    text = Column(Text, nullable=False)
    extracted_text = Column(Text)  # OCR'd text from screenshots
    posted_date = Column(DateTime, index=True)
    captured_date = Column(DateTime, default=datetime.utcnow, index=True)
    
    # Screenshots and media
    screenshot_path = Column(String)  # Local screenshot file
    media_urls = Column(JSON)  # List of media URLs
    media_paths = Column(JSON)  # Local paths to downloaded media
    
    # Analysis
    sentiment = Column(String)  # positive, negative, neutral
    engagement_metrics = Column(JSON)  # likes, retweets, comments, shares
    mentioned_politicians = Column(JSON)
    mentioned_topics = Column(JSON)
    
    # Status
    is_processed = Column(Boolean, default=False)
    used_in_articles = Column(JSON)  # List of generated article IDs using this post
    
    def __repr__(self):
        return f"<SocialMediaPost(author='{self.author_username}', platform='{self.platform}')>"


class GeneratedArticle(Base):
    """Articles generated by the think tank system"""
    __tablename__ = "generated_articles"
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    article_type = Column(String, nullable=False, index=True)  # historical, present, future
    title = Column(String, nullable=False)
    content = Column(Text, nullable=False)
    
    # Topic and analysis
    topic = Column(String, nullable=False, index=True)
    analysis_depth = Column(String)  # shallow, medium, deep
    
    # Source materials
    source_articles = relationship("Article", secondary="generated_article_sources")
    source_social_posts = relationship("SocialMediaPost", secondary="generated_article_sources_social")
    
    # Analysis metadata
    analysis_data = Column(JSON)  # Full analysis data (trends, predictions, etc.)
    confidence_score = Column(Float)  # 0-1 confidence in generation
    
    # Generation metadata
    generated_date = Column(DateTime, default=datetime.utcnow, index=True)
    generated_by = Column(String)  # "template-based", "llm-enhanced", etc.
    
    # Publication status
    status = Column(String, default="draft", index=True)  # draft, flagged_for_review, published, archived
    review_notes = Column(Text)  # For flagged articles
    review_date = Column(DateTime)
    reviewed_by = Column(String)
    published_date = Column(DateTime)
    
    # Metrics
    view_count = Column(Integer, default=0)
    engagement_count = Column(Integer, default=0)
    
    # Sections (can be stored as JSON for better querying)
    sections = Column(JSON)  # Dict of section_name -> section_content
    
    # User-driven contributions
    article_request_id = Column(String, ForeignKey("article_requests.id"))  # If from user request
    user_thinking_sources = relationship("UserThinking", secondary="article_request_thinking")
    user_provided_context = Column(Text)  # Combined context from user thinking
    
    def __repr__(self):
        return f"<GeneratedArticle(type='{self.article_type}', topic='{self.topic}')>"


class AnalysisTrend(Base):
    """Stores identified trends and patterns"""
    __tablename__ = "analysis_trends"
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    trend_name = Column(String, nullable=False, index=True)
    category = Column(String)  # topic, politician, organization, etc.
    
    # Time period
    start_date = Column(DateTime, nullable=False)
    end_date = Column(DateTime, nullable=False)
    window_days = Column(Integer)  # Analysis window
    
    # Trend data
    mention_count = Column(Integer)  # How many times mentioned
    sentiment_breakdown = Column(JSON)  # {positive: x, negative: y, neutral: z}
    related_trends = Column(JSON)  # List of related trend IDs
    articles_count = Column(Integer)  # Number of articles covering this
    
    # Impact
    trend_strength = Column(Float)  # 0-1, how strong is this trend
    growth_rate = Column(Float)  # Rate of growth/decline
    
    # Prediction
    predicted_trajectory = Column(String)  # ascending, descending, stable
    confidence = Column(Float)  # Confidence in prediction
    
    created_date = Column(DateTime, default=datetime.utcnow)
    
    def __repr__(self):
        return f"<AnalysisTrend(name='{self.trend_name}', period={self.window_days}d)>"


class Prediction(Base):
    """Stores made predictions for tracking and validation"""
    __tablename__ = "predictions"
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    
    # Prediction details
    topic = Column(String, nullable=False, index=True)
    prediction_type = Column(String)  # outcome, trend, event, etc.
    prediction_text = Column(Text, nullable=False)
    
    # Time horizon
    made_date = Column(DateTime, default=datetime.utcnow, index=True)
    forecast_date = Column(DateTime, nullable=False, index=True)  # When prediction is for
    forecast_days = Column(Integer)  # How many days in the future
    
    # Confidence
    confidence_level = Column(Float)  # 0-1
    supporting_factors = Column(JSON)  # List of factors supporting this prediction
    risk_factors = Column(JSON)  # List of risk factors
    
    # Outcome tracking
    actual_outcome = Column(Text)  # What actually happened
    outcome_date = Column(DateTime)
    outcome_accuracy = Column(Float)  # 0-1, how accurate was the prediction
    validation_status = Column(String)  # validated, failed, pending, partially_true
    
    def __repr__(self):
        return f"<Prediction(topic='{self.topic}', forecast={self.forecast_days}d)>"


class ContentSource(Base):
    """Tracks RSS feeds and social media sources being monitored"""
    __tablename__ = "content_sources"
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    source_type = Column(String)  # rss, twitter, facebook, instagram
    name = Column(String, nullable=False, index=True)
    url = Column(String)
    username = Column(String)  # For social media
    
    # Source metadata
    category = Column(String)  # news, politics, economy, etc.
    priority = Column(Integer)  # 1-10, higher = more important
    is_active = Column(Boolean, default=True, index=True)
    
    # Monitoring
    last_fetch_date = Column(DateTime)
    fetch_frequency_minutes = Column(Integer, default=60)
    articles_fetched = Column(Integer, default=0)
    
    # Stats
    avg_relevance_score = Column(Float)  # Average relevance of articles from this source
    total_articles = Column(Integer, default=0)
    
    created_date = Column(DateTime, default=datetime.utcnow)
    updated_date = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    
    def __repr__(self):
        return f"<ContentSource(name='{self.name}', type='{self.source_type}')>"


class PublicationQueue(Base):
    """Queue for publishing generated articles with approval workflow"""
    __tablename__ = "publication_queue"
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    generated_article_id = Column(String, ForeignKey("generated_articles.id"), nullable=False)
    
    # Workflow
    status = Column(String, default="pending", index=True)  # pending, approved, rejected, published
    reason_flagged = Column(Text)  # Why this article was flagged (if applicable)
    uncertainty_level = Column(String)  # high, medium, low
    
    # Review tracking
    submitted_date = Column(DateTime, default=datetime.utcnow)
    review_date = Column(DateTime)
    reviewed_by = Column(String)
    reviewer_notes = Column(Text)
    
    # Publication
    scheduled_publish_date = Column(DateTime)
    actual_publish_date = Column(DateTime)
    
    def __repr__(self):
        return f"<PublicationQueue(article_id='{self.generated_article_id}', status='{self.status}')>"


# Association tables for many-to-many relationships
from sqlalchemy import Table

generated_article_sources = Table(
    "generated_article_sources",
    Base.metadata,
    Column("generated_article_id", String, ForeignKey("generated_articles.id"), primary_key=True),
    Column("article_id", String, ForeignKey("articles.id"), primary_key=True)
)

generated_article_sources_social = Table(
    "generated_article_sources_social",
    Base.metadata,
    Column("generated_article_id", String, ForeignKey("generated_articles.id"), primary_key=True),
    Column("social_media_post_id", String, ForeignKey("social_media_posts.id"), primary_key=True)
)

generated_article_sources_scraped = Table(
    "generated_article_sources_scraped",
    Base.metadata,
    Column("generated_article_id", String, ForeignKey("generated_articles.id"), primary_key=True),
    Column("scraped_article_id", String, ForeignKey("scraped_articles.id"), primary_key=True)
)


class ScrapedArticle(Base):
    """Articles scraped from news websites (not from RSS)"""
    __tablename__ = "scraped_articles"
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    
    # Article content
    title = Column(String, nullable=False, index=True)
    content = Column(Text)
    url = Column(String, unique=True, nullable=False)
    source_site = Column(String, nullable=False, index=True)  # e.g., "herald.co.zw"
    source_category = Column(String)  # zimbabwe_local, regional_african, international
    
    # Metadata
    author = Column(String)
    published_date = Column(DateTime, index=True)
    scraped_date = Column(DateTime, default=datetime.utcnow, index=True)
    
    # Content analysis
    relevance_score = Column(Float)  # 0-1 Zimbabwe relevance
    category = Column(String)  # Politics, Economy, Tech, etc.
    sentiment = Column(String)  # positive, negative, neutral
    
    # Extracted entities
    mentioned_politicians = Column(JSON)  # List of politicians
    mentioned_organizations = Column(JSON)  # List of organizations
    mentioned_locations = Column(JSON)  # List of locations
    keywords = Column(JSON)  # Key topics
    
    # Media
    image_url = Column(String)
    image_path = Column(String)
    image_count = Column(Integer, default=0)  # Number of images in article
    
    # Duplicate tracking
    is_duplicate = Column(Boolean, default=False, index=True)
    duplicate_of_id = Column(String)  # Reference to original if this is duplicate
    duplicate_sources = Column(JSON)  # List of other URLs with same/similar content
    
    # Status
    is_processed = Column(Boolean, default=False)
    used_in_articles = Column(JSON)  # List of generated article IDs
    is_archived = Column(Boolean, default=False)
    
    # Scraper metadata
    scraper_method = Column(String)  # xpath, css, beautifulsoup, etc.
    extraction_confidence = Column(Float)  # How confident is the extraction
    
    created_date = Column(DateTime, default=datetime.utcnow)
    updated_date = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    
    def __repr__(self):
        return f"<ScrapedArticle(title='{self.title[:50]}', source='{self.source_site}')>"


class ContentDuplicate(Base):
    """Tracks duplicate/similar content across sources"""
    __tablename__ = "content_duplicates"
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    
    # Canonical content (the "main" version)
    canonical_article_id = Column(String, index=True)
    canonical_source = Column(String)  # articles, scraped_articles, social_media_posts
    
    # Related content (duplicates/similar versions)
    related_article_id = Column(String, index=True)
    related_source = Column(String)  # articles, scraped_articles, social_media_posts
    
    # Similarity metrics
    title_similarity = Column(Float)  # 0-1 title match
    content_similarity = Column(Float)  # 0-1 content match (Levenshtein/cosine)
    duplicate_type = Column(String)  # exact, near_duplicate, same_story_different_angle, same_topic
    
    # Metadata
    detected_date = Column(DateTime, default=datetime.utcnow)
    manual_review = Column(Boolean, default=False)
    is_verified = Column(Boolean, default=False)
    
    def __repr__(self):
        return f"<ContentDuplicate(canonical='{self.canonical_article_id}', related='{self.related_article_id}')>"


class WebScraperConfig(Base):
    """Configuration for web scraper targets"""
    __tablename__ = "web_scraper_configs"
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    
    # Target info
    site_name = Column(String, nullable=False, index=True)
    site_url = Column(String, nullable=False)
    source_category = Column(String)  # zimbabwe_local, regional_african, international
    
    # Scraping configuration
    scraper_type = Column(String)  # xpath, css, beautifulsoup, selenium
    article_selector = Column(String)  # CSS/XPath selector for articles
    title_selector = Column(String)
    content_selector = Column(String)
    author_selector = Column(String)
    date_selector = Column(String)
    image_selector = Column(String)
    
    # Pagination
    pagination_type = Column(String)  # none, next_button, page_number, infinite_scroll
    pagination_selector = Column(String)
    
    # Monitoring
    is_active = Column(Boolean, default=True, index=True)
    scrape_interval_minutes = Column(Integer, default=120)
    last_scrape_date = Column(DateTime)
    last_scrape_status = Column(String)  # success, failed, partial
    
    # Stats
    total_articles_scraped = Column(Integer, default=0)
    avg_relevance_score = Column(Float)
    
    # Schedule
    enabled_days = Column(JSON)  # List of days to scrape (0=Monday, 6=Sunday)
    enabled_hours = Column(JSON)  # List of hours (0-23)
    
    created_date = Column(DateTime, default=datetime.utcnow)
    updated_date = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    
    def __repr__(self):
        return f"<WebScraperConfig(site='{self.site_name}', category='{self.source_category}')>"


class User(Base):
    """Registered users who can request articles and contribute thinking"""
    __tablename__ = "users"
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    
    # User info
    username = Column(String, nullable=False, unique=True, index=True)
    email = Column(String, nullable=False, unique=True, index=True)
    full_name = Column(String)
    
    # Authentication (store hashed password in production)
    password_hash = Column(String, nullable=False)
    is_active = Column(Boolean, default=True)
    
    # Roles and permissions
    role = Column(String, default="analyst")  # analyst, reviewer, admin
    permissions = Column(JSON)  # List of specific permissions
    
    # Profile
    bio = Column(Text)
    expertise_areas = Column(JSON)  # Topics they specialize in
    
    # Activity tracking
    created_date = Column(DateTime, default=datetime.utcnow, index=True)
    last_login = Column(DateTime)
    articles_requested = Column(Integer, default=0)
    thinking_contributions = Column(Integer, default=0)
    
    # Relationships
    article_requests = relationship("ArticleRequest", back_populates="requested_by")
    thinking_contributions_rel = relationship("UserThinking", back_populates="contributed_by")
    
    def __repr__(self):
        return f"<User(username='{self.username}', role='{self.role}')>"


class ArticleRequest(Base):
    """User requests for specific articles to be written"""
    __tablename__ = "article_requests"
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    
    # Request details
    title = Column(String, nullable=False, index=True)
    topic = Column(String, nullable=False, index=True)
    desired_angle = Column(Text)  # Specific perspective/angle to take
    
    # Specifications
    key_points = Column(JSON)  # List of key points to include
    required_sources = Column(JSON)  # List of source URLs or source types to include
    exclude_sources = Column(JSON)  # Sources to avoid
    
    # Article parameters
    article_type = Column(String)  # historical, present, future, analysis
    estimated_length = Column(String, default="medium")  # short, medium, long
    target_audience = Column(String)  # policymakers, general_public, investors, academics
    
    # User input
    background_context = Column(Text)  # Why this article is needed
    deadline = Column(DateTime)  # When article is needed
    
    # Metadata
    status = Column(String, default="pending", index=True)  # pending, assigned, in_progress, completed, rejected
    priority = Column(Integer, default=1)  # 1-5, higher = more urgent
    
    # User and tracking
    requested_by_id = Column(String, ForeignKey("users.id"), nullable=False, index=True)
    requested_by = relationship("User", back_populates="article_requests")
    
    # Generated article link
    generated_article_id = Column(String, ForeignKey("generated_articles.id"))
    
    # Status updates
    created_date = Column(DateTime, default=datetime.utcnow, index=True)
    assigned_date = Column(DateTime)
    completed_date = Column(DateTime)
    rejection_reason = Column(Text)  # Why rejected if status = rejected
    
    # Relationships
    thinking_contributions = relationship("UserThinking", back_populates="article_request")
    
    def __repr__(self):
        return f"<ArticleRequest(topic='{self.topic}', status='{self.status}')>"


class UserThinking(Base):
    """User contributions and thinking during article construction"""
    __tablename__ = "user_thinking"
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    
    # Association
    article_request_id = Column(String, ForeignKey("article_requests.id"), nullable=True, index=True)
    article_request = relationship("ArticleRequest", back_populates="thinking_contributions")
    
    generated_article_id = Column(String, ForeignKey("generated_articles.id"), nullable=True, index=True)
    
    # User contribution
    contributed_by_id = Column(String, ForeignKey("users.id"), nullable=False, index=True)
    contributed_by = relationship("User", back_populates="thinking_contributions_rel")
    
    # Stage of article construction
    stage = Column(String, nullable=False, index=True)  # pre_generation, draft_review, refinement, final
    
    # Content
    thinking_content = Column(Text, nullable=False)
    thinking_type = Column(String)  # suggestion, perspective, fact_check, improvement, analysis
    
    # Impact tracking
    was_used = Column(Boolean, default=False)  # Whether this thinking was incorporated
    impact_notes = Column(Text)  # How it was used or why it wasn't used
    
    # Metadata
    created_date = Column(DateTime, default=datetime.utcnow, index=True)
    updated_date = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    is_visible_to_team = Column(Boolean, default=True)  # Internal tracking only by default
    
    # Scoring
    helpfulness_score = Column(Float)  # 0-1, how helpful was this contribution
    adoption_priority = Column(Integer)  # 0-10, priority for incorporation
    
    def __repr__(self):
        return f"<UserThinking(stage='{self.stage}', type='{self.thinking_type}')>"


# Association table for thinking to generated articles (many-to-many)
article_request_thinking = Table(
    "article_request_thinking",
    Base.metadata,
    Column("article_request_id", String, ForeignKey("article_requests.id"), primary_key=True),
    Column("user_thinking_id", String, ForeignKey("user_thinking.id"), primary_key=True)
)


# Update GeneratedArticle relationship to include user requests and thinking
# This would need to be added to the GeneratedArticle class:
# article_request_id = Column(String, ForeignKey("article_requests.id"))
# user_thinking_sources = relationship("UserThinking", secondary="article_request_thinking")
